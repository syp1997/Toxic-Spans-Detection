{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bCOPRfXOyx7S",
    "outputId": "1111b54c-6f23-4da4-b67a-f4b26fc71487"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'toxic_spans' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ipavlopoulos/toxic_spans.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HOkoyQsdzULS",
    "outputId": "099176d8-ab24-4e7b-98f4-ee5bf08763c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.douban.com/simple/\n",
      "Requirement already satisfied: transformers in /home/suyinpei/anaconda3/envs/syp/lib/python3.8/site-packages (4.5.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/suyinpei/anaconda3/envs/syp/lib/python3.8/site-packages (from transformers) (4.60.0)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /home/suyinpei/anaconda3/envs/syp/lib/python3.8/site-packages (from transformers) (0.10.2)\n",
      "Requirement already satisfied: requests in /home/suyinpei/anaconda3/envs/syp/lib/python3.8/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/suyinpei/anaconda3/envs/syp/lib/python3.8/site-packages (from transformers) (1.20.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/suyinpei/anaconda3/envs/syp/lib/python3.8/site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: sacremoses in /home/suyinpei/anaconda3/envs/syp/lib/python3.8/site-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: filelock in /home/suyinpei/anaconda3/envs/syp/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: packaging in /home/suyinpei/anaconda3/envs/syp/lib/python3.8/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/suyinpei/anaconda3/envs/syp/lib/python3.8/site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/suyinpei/anaconda3/envs/syp/lib/python3.8/site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/suyinpei/anaconda3/envs/syp/lib/python3.8/site-packages (from requests->transformers) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/suyinpei/anaconda3/envs/syp/lib/python3.8/site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/suyinpei/anaconda3/envs/syp/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: click in /home/suyinpei/anaconda3/envs/syp/lib/python3.8/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /home/suyinpei/anaconda3/envs/syp/lib/python3.8/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in /home/suyinpei/anaconda3/envs/syp/lib/python3.8/site-packages (from sacremoses->transformers) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nnfu24uHzXsI",
    "outputId": "f288834a-004b-49f1-cd4b-46be7332041c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr 29 17:19:47 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-PCIE...  Off  | 00000000:00:05.0 Off |                    0 |\n",
      "| N/A   38C    P0    30W / 250W |      4MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-PCIE...  Off  | 00000000:00:06.0 Off |                    0 |\n",
      "| N/A   37C    P0    24W / 250W |      4MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LLCJZi3by5WG"
   },
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import os\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "fnjxVa0OVNea"
   },
   "outputs": [],
   "source": [
    "# set up logging\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO,\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.getLogger('transformers').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "RmjKQ3cXSelg"
   },
   "outputs": [],
   "source": [
    "translationTable = str.maketrans(\"éàèùaêóïüÉ\",\"eaeuaeoiuE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "9dYjJLf3y5YO",
    "outputId": "72f1b939-79a1-412b-e9f8-f4fed8d971a9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spans</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7934</th>\n",
       "      <td>[8, 9, 10, 11]</td>\n",
       "      <td>Another fool pipes in.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7935</th>\n",
       "      <td>[48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 5...</td>\n",
       "      <td>So if a restaurant owner puts up a sign saying...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7936</th>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>Any faith that can't stand up to logic and rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7937</th>\n",
       "      <td>[5, 6, 7, 8, 9, 10, 11]</td>\n",
       "      <td>This idiotic. Use the surplus to pay down the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7938</th>\n",
       "      <td>[106, 107, 108, 109, 110, 169, 170, 171, 172, ...</td>\n",
       "      <td>Who is this \"we\" of which you speak? Are you r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  spans  \\\n",
       "7934                                     [8, 9, 10, 11]   \n",
       "7935  [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 5...   \n",
       "7936  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "7937                            [5, 6, 7, 8, 9, 10, 11]   \n",
       "7938  [106, 107, 108, 109, 110, 169, 170, 171, 172, ...   \n",
       "\n",
       "                                                   text  \n",
       "7934                             Another fool pipes in.  \n",
       "7935  So if a restaurant owner puts up a sign saying...  \n",
       "7936  Any faith that can't stand up to logic and rea...  \n",
       "7937  This idiotic. Use the surplus to pay down the ...  \n",
       "7938  Who is this \"we\" of which you speak? Are you r...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsd = pd.read_csv(\"toxic_spans/data/tsd_train.csv\") \n",
    "tsd.text = tsd.text.apply(lambda x:x.translate(translationTable))\n",
    "tsd.spans = tsd.spans.apply(literal_eval)\n",
    "tsd.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tm6qdnG9y5ao"
   },
   "outputs": [],
   "source": [
    "text_list = tsd.text.to_list()\n",
    "spans_list = tsd.spans.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EckJscETy5ck",
    "outputId": "30b7be95-e3bb-408f-c05f-2aaa41b4c81f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7939\n",
      "7939\n"
     ]
    }
   ],
   "source": [
    "print(len(text_list))\n",
    "print(len(spans_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_data = torch.load(\"augmented_data_all.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list_aug = [i['text_aug'] for i in augment_data]\n",
    "spans_list_aug = [i['spans_aug'] for i in augment_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40904\n",
      "40904\n"
     ]
    }
   ],
   "source": [
    "print(len(text_list_aug))\n",
    "print(len(spans_list_aug))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_list += text_list_aug\n",
    "# spans_list += spans_list_aug\n",
    "# print(len(text_list))\n",
    "# print(len(spans_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "1mtyJRFQxbW6",
    "outputId": "4751dc17-6a01-4515-89ad-1e7547b1c955"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spans</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>[129, 130, 131, 132, 133, 134]</td>\n",
       "      <td>But ... Trump's not bluffing. He's prepared to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>[126, 127, 128, 129, 130, 131]</td>\n",
       "      <td>Can't believe the limited knowledge of this Ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>[24, 25, 26, 27, 28, 29]</td>\n",
       "      <td>I think it conservative idiots who cannot reac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>You're an id*ot...Go away.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>[136, 137, 138, 139, 140, 141]</td>\n",
       "      <td>Unless there is wording in the employment cont...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 spans  \\\n",
       "685                     [129, 130, 131, 132, 133, 134]   \n",
       "686                     [126, 127, 128, 129, 130, 131]   \n",
       "687                           [24, 25, 26, 27, 28, 29]   \n",
       "688  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "689                     [136, 137, 138, 139, 140, 141]   \n",
       "\n",
       "                                                  text  \n",
       "685  But ... Trump's not bluffing. He's prepared to...  \n",
       "686  Can't believe the limited knowledge of this Ar...  \n",
       "687  I think it conservative idiots who cannot reac...  \n",
       "688                         You're an id*ot...Go away.  \n",
       "689  Unless there is wording in the employment cont...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsd2 = pd.read_csv(\"toxic_spans/data/tsd_trial.csv\") \n",
    "tsd2.text = tsd2.text.apply(lambda x:x.translate(translationTable))\n",
    "tsd2.spans = tsd2.spans.apply(literal_eval)\n",
    "tsd2.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "KeRr4O-lxiw5"
   },
   "outputs": [],
   "source": [
    "text_valid = tsd2.text.to_list()\n",
    "spans_valid = tsd2.spans.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3GtWXHzAxizD",
    "outputId": "8472d31b-74f2-41cc-8f4a-b12a8ca1c36c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690\n",
      "690\n"
     ]
    }
   ],
   "source": [
    "print(len(text_valid))\n",
    "print(len(spans_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "bmMMvE4McZQO"
   },
   "outputs": [],
   "source": [
    "model_name = \"google/electra-large-discriminator\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369,
     "referenced_widgets": [
      "b1c2b0adacf446b4803918935f5f84b7",
      "7c49fa8b83854ff2bfdf878987536143",
      "e682f84e614246dbafd326a37755abca",
      "cfc78163ca96469fa6fecea3f2b2c7cd",
      "388526bae29e43fd901423b040e4fdca",
      "8e2fe1d6c8b44ccdbf6387f5a083a588",
      "a5eb5d9f44ec461ba0d37fdf71382dfe",
      "afcdb17041fc42078c8227a570e23c1a",
      "91a6c01d5d504325823ea2ad3ea7e64c",
      "2748949795714def9ae46211d9a26935",
      "956b8371f8844f9ba716b6ededeacded",
      "f909863f47584c97a491dc45389c90fe",
      "7afd432af34c4e3eab15861550363787",
      "c6f44b8c16af4411a63e8312ed539a7b",
      "2450ea27dfe749d690d52a6adb0df8f6",
      "fce5824b50b14ed3a04c85dadf2017a3",
      "53fe88b22070493f8477ee24f9f1d86c",
      "85112c4d55f14fccb486a5ad73898c62",
      "286c30e0462a4dff9076b75aa3933703",
      "bf0b1c6f927d47f1bdcd8d3ee9354234",
      "20b585c719c4416990562e924fda411d",
      "66b05ef2743d49f182a63db56ed34270",
      "bdc6bae7c32b413280158502bda24845",
      "ea1cc8393c7e44f9be293d0257246f2a",
      "5b903d2bcd1e41ba91114e2d42f83d99",
      "2d4ad0920c9946d58c3591b834fc321e",
      "0730a084aa4a4926841711e099242b66",
      "20f7d4b0e142411d97426d6b26766b81",
      "23af761282a04e6787541cf8956d963c",
      "195068b301e34121bf94b1f2ae26466e",
      "ec476a28a4144d68b09eb39fab1fe1ae",
      "e8693669133e4e7d8eb891641d04a404"
     ]
    },
    "id": "fi7nb_gjzNvr",
    "outputId": "9ca65dc1-e4be-42b3-b4ae-294a76fe590b"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "zkRGzg9AIFsa"
   },
   "outputs": [],
   "source": [
    "special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "5ciQ8nVh6Paz"
   },
   "outputs": [],
   "source": [
    "def find_idx(sentence, token, position=0):\n",
    "    start = sentence.find(token, position)\n",
    "    end = start + len(token)\n",
    "    if start == -1:\n",
    "        return []\n",
    "    return list(range(start,end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "DcRW8DlKGeBW"
   },
   "outputs": [],
   "source": [
    "def encode_and_trans_labels(text_list, spans_list):\n",
    "    inputs = tokenizer(\n",
    "        text_list,                      \n",
    "        add_special_tokens = True,             \n",
    "        truncation=True,\n",
    "        padding = 'max_length',     \n",
    "        return_tensors = 'pt',\n",
    "        max_length = 128\n",
    "    )\n",
    "    input_ids = inputs['input_ids']\n",
    "    attention_mask = inputs['attention_mask']\n",
    "\n",
    "    labels = []\n",
    "    for it, (ids, sentence, toxic_spans) in enumerate(zip(input_ids, text_list, spans_list)):\n",
    "        # print(sentence)\n",
    "        # print(toxic_spans)\n",
    "        # print(it)\n",
    "        tokens = tokenizer.convert_ids_to_tokens(ids)\n",
    "        token_labels = []\n",
    "        position = 0\n",
    "        for token in tokens[:]:\n",
    "            if token in special_tokens.values():\n",
    "                token_labels.append(0.)\n",
    "            else:\n",
    "                token = token.replace(\"##\",\"\")\n",
    "                spans = find_idx(sentence.lower(), token, position=position)\n",
    "                if spans == []:\n",
    "                    spans = list(range(position,position+len(token)))\n",
    "                    print(\"not find:\",token,spans,position,[sentence[i] for i in spans])\n",
    "                # print(token,spans,position)\n",
    "                position = spans[-1]+1\n",
    "                if set(spans[:]) <= set(toxic_spans) or (set(toxic_spans)<=set(spans) and len(set(toxic_spans))>0):\n",
    "                    token_labels.append(1.)\n",
    "                elif len(set(spans[:-1])) > 0 and (set(spans[:-1]) <= set(toxic_spans)):\n",
    "                    # print(token, spans, toxic_spans)\n",
    "                    token_labels.append(1.)\n",
    "                else:\n",
    "                    token_labels.append(0.)\n",
    "                # print(token,spans,position)\n",
    "        labels.append(token_labels)\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    return input_ids, attention_mask, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "D1cKOCLgPGV1"
   },
   "outputs": [],
   "source": [
    "class TextDataSet(Dataset):\n",
    "    def __init__(self, input_ids, attention_mask, labels, text_list, spans_list):\n",
    "        self.input_ids = input_ids\n",
    "        self.attention_mask = attention_mask\n",
    "        self.labels = labels\n",
    "        self.text_list = text_list\n",
    "        self.spans_list = spans_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):   \n",
    "        return (self.input_ids[idx], self.attention_mask[idx], self.labels[idx], self.text_list[idx], self.spans_list[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "woc4aK2DHLm-"
   },
   "outputs": [],
   "source": [
    "input_ids_aug,attention_mask_aug,labels_aug = encode_and_trans_labels(text_list_aug, spans_list_aug)\n",
    "input_ids,attention_mask,labels = encode_and_trans_labels(text_list, spans_list)\n",
    "input_ids_valid,attention_mask_valid,labels_valid = encode_and_trans_labels(text_valid, spans_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vWPx6ernNhL7",
    "outputId": "67a59b68-747c-4ed2-c256-b993351500c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented samples: 40904, Train samples: 7939, Valid samples: 690\n"
     ]
    }
   ],
   "source": [
    "train_dataset_aug = TextDataSet(input_ids_aug,attention_mask_aug,labels_aug, text_list_aug, spans_list_aug)\n",
    "train_dataset = TextDataSet(input_ids, attention_mask, labels, text_list, spans_list)\n",
    "valid_dataset = TextDataSet(input_ids_valid,attention_mask_valid,labels_valid, text_valid, spans_valid)\n",
    "# train_size = int(len(dataset)*0.8)\n",
    "# valid_size = len(dataset)-train_size\n",
    "# train_dataset, valid_dataset = random_split(dataset, [train_size,valid_size])\n",
    "print('Augmented samples: {}, Train samples: {}, Valid samples: {}'.format(len(train_dataset_aug), len(train_dataset), len(valid_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "3r5iu0GmPJD1"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import collections\n",
    "from torch._six import string_classes\n",
    "\n",
    "np_str_obj_array_pattern = re.compile(r'[SaUO]')\n",
    "\n",
    "def default_collate(batch):\n",
    "    r\"\"\"Puts each data field into a tensor with outer dimension batch size\"\"\"\n",
    "\n",
    "    elem = batch[0]\n",
    "    elem_type = type(elem)\n",
    "    if isinstance(elem, torch.Tensor):\n",
    "        out = None\n",
    "        if torch.utils.data.get_worker_info() is not None:\n",
    "            # If we're in a background process, concatenate directly into a\n",
    "            # shared memory tensor to avoid an extra copy\n",
    "            numel = sum([x.numel() for x in batch])\n",
    "            storage = elem.storage()._new_shared(numel)\n",
    "            out = elem.new(storage)\n",
    "        return torch.stack(batch, 0, out=out)\n",
    "    elif elem_type.__module__ == 'numpy' and elem_type.__name__ != 'str_' \\\n",
    "            and elem_type.__name__ != 'string_':\n",
    "        if elem_type.__name__ == 'ndarray' or elem_type.__name__ == 'memmap':\n",
    "            # array of string classes and object\n",
    "            if np_str_obj_array_pattern.search(elem.dtype.str) is not None:\n",
    "                raise TypeError(default_collate_err_msg_format.format(elem.dtype))\n",
    "\n",
    "            return default_collate([torch.as_tensor(b) for b in batch])\n",
    "        elif elem.shape == ():  # scalars\n",
    "            return torch.as_tensor(batch)\n",
    "    elif isinstance(elem, float):\n",
    "        return torch.tensor(batch, dtype=torch.float64)\n",
    "    elif isinstance(elem, int):\n",
    "        return torch.tensor(batch)\n",
    "    elif isinstance(elem, string_classes):\n",
    "        return batch\n",
    "    elif isinstance(elem, list):\n",
    "        return batch\n",
    "    elif isinstance(elem, collections.abc.Mapping):\n",
    "        return {key: default_collate([d[key] for d in batch]) for key in elem}\n",
    "    elif isinstance(elem, tuple) and hasattr(elem, '_fields'):  # namedtuple\n",
    "        return elem_type(*(default_collate(samples) for samples in zip(*batch)))\n",
    "    elif isinstance(elem, collections.abc.Sequence):\n",
    "        # check to make sure that the elements in batch have consistent size\n",
    "        it = iter(batch)\n",
    "        elem_size = len(next(it))\n",
    "        if not all(len(elem) == elem_size for elem in it):\n",
    "            raise RuntimeError('each element in list of batch should be of equal size')\n",
    "        transposed = zip(*batch)\n",
    "        return [default_collate(samples) for samples in transposed]\n",
    "\n",
    "    raise TypeError(default_collate_err_msg_format.format(elem_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "TXuDXs6LNhOa"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_loader_aug = DataLoader(train_dataset_aug, batch_size=batch_size, shuffle=True, collate_fn=default_collate)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=default_collate)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True, collate_fn=default_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120,
     "referenced_widgets": [
      "21e445d606a143d6ad599668523ec7da",
      "57e4fabc60f6407da277eef042ee5955",
      "54eb2ccca1b84689ae3cc02deabc9fd9",
      "31d43e06bf4c41ceade9758bf89d28ec",
      "85ca440b2bcc4f0ca0b9b131a12e17e8",
      "f61b392045c24f9d871bfab43164b1a8",
      "361b7ec51ba847c4a291bc409e1d1010",
      "2eaf2d8bd4b541d9a46da132f7e4e501"
     ]
    },
    "id": "R_fq789fH5C3",
    "outputId": "5fa9aa38-c9be-4def-80c4-a9959b37fff5"
   },
   "outputs": [],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "tDYLv3fVos2o"
   },
   "outputs": [],
   "source": [
    "weight_CE = torch.FloatTensor([1,0.55]).to(device)\n",
    "loss_fct = nn.CrossEntropyLoss(weight=weight_CE)\n",
    "def loss_fn(logits, attention_mask, labels):\n",
    "    active_loss = attention_mask.view(-1) == 1\n",
    "    active_logits = logits.view(-1, 2)\n",
    "    active_labels = torch.where(\n",
    "        active_loss, labels.view(-1), torch.tensor(loss_fct.ignore_index).type_as(labels)\n",
    "    )\n",
    "    loss = loss_fct(active_logits, active_labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "YiX-OyyOL4wy"
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "\n",
    "    def __init__(self, model, train_loader, valid_loader, config):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.valid_loader = valid_loader\n",
    "        self.config = config\n",
    "\n",
    "        # take over whatever gpus are on the system\n",
    "        self.device = 'cpu'\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.cuda.current_device()\n",
    "            self.model = torch.nn.DataParallel(self.model).to(self.device)\n",
    "\n",
    "    def save_checkpoint(self):\n",
    "        # DataParallel wrappers keep raw model object in .module attribute\n",
    "        raw_model = self.model.module if hasattr(self.model, \"module\") else self.model\n",
    "        os.makedirs(self.config.ckpt_path, exist_ok=True)\n",
    "        logger.info(\"Save model to {}\".format(self.config.ckpt_path))\n",
    "        torch.save(raw_model.state_dict(), self.config.ckpt_path+\"best_model.pt\")\n",
    "\n",
    "    def train(self):\n",
    "        model, config = self.model, self.config\n",
    "        raw_model = model.module if hasattr(self.model, \"module\") else model\n",
    "        optimizer = torch.optim.AdamW(self.model.parameters(), lr=config.learning_rate, betas=config.betas)\n",
    "        def run_epoch(split):\n",
    "            is_train = (split == 'train')\n",
    "            model.train(is_train)\n",
    "            loader = self.train_loader if is_train else self.valid_loader\n",
    "            losses = []\n",
    "            spans_list_all = []\n",
    "            spans_pred_all = []\n",
    "            pbar = tqdm(enumerate(loader), total=len(loader)) if is_train else enumerate(loader)\n",
    "            for it, (input_ids, attention_mask, y, text_list, spans_list) in pbar:\n",
    "                # place data on the correct device\n",
    "                input_ids = input_ids.to(self.device)\n",
    "                attention_mask = attention_mask.to(self.device)\n",
    "                y = y.to(self.device).long()\n",
    "                # forward the model\n",
    "                with torch.set_grad_enabled(is_train):\n",
    "                    outputs = model(input_ids, attention_mask, labels=y)\n",
    "                    logits = outputs.logits\n",
    "                    # loss = outputs.loss\n",
    "                    loss = loss_fn(logits, attention_mask, y)\n",
    "#                     loss = loss.mean() # collapse all losses if they are scattered on multiple gpus\n",
    "                    losses.append(loss.item())\n",
    "\n",
    "                    spans_pred = decode_and_trans_labels(text_list, input_ids, logits)\n",
    "                    # print(\"pred: \",spans_pred)\n",
    "                    # print(\"gold: \",spans_list)\n",
    "                    f1_score, recall_score, precision_score = batch_score(spans_pred, spans_list)\n",
    "\n",
    "                    spans_list_all.extend(spans_list)\n",
    "                    spans_pred_all.extend(spans_pred)\n",
    "\n",
    "                    # gold = (\"\".join(text_list[0][i] for i in spans_list[0])).lower()\n",
    "                    # spans_labels = torch.nonzero(y[0].cpu().detach())\n",
    "                    # spans_labels = tokenizer.convert_ids_to_tokens([input_ids[0][i] for i in spans_labels])\n",
    "                    # spans_labels = \"\".join([i.replace(\"##\",\"\") for i in spans_labels])\n",
    "                    # pred = \"\".join(text_list[0][i] for i in spans_pred[0])\n",
    "                    # print(\"\\ngold: {}\\nlables: {}\\npred: {}\".format(gold,spans_labels,pred))\n",
    "                \n",
    "                if is_train:\n",
    "\n",
    "                    # backprop and update the parameters\n",
    "                    model.zero_grad()\n",
    "                    loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), config.grad_norm_clip)\n",
    "                    optimizer.step()\n",
    "\n",
    "                    # decay the learning rate based on our progress\n",
    "                    if config.lr_decay:\n",
    "                        self.tokens += batch_size # number of tokens processed this step (i.e. label is not -100)\n",
    "                        if self.tokens < config.warmup_tokens:\n",
    "                            # linear warmup\n",
    "                            lr_mult = float(self.tokens) / float(max(1, config.warmup_tokens))\n",
    "                        else:\n",
    "                            # cosine learning rate decay\n",
    "                            progress = float(self.tokens - config.warmup_tokens) / float(max(1, config.final_tokens - config.warmup_tokens))\n",
    "                            lr_mult = max(0.1, 0.5 * (1.0 + math.cos(math.pi * progress)))\n",
    "                        lr = config.learning_rate * lr_mult\n",
    "                        for param_group in optimizer.param_groups:\n",
    "                            param_group['lr'] = lr\n",
    "                    else:\n",
    "                        lr = config.learning_rate\n",
    "\n",
    "                    # report progress\n",
    "                    pbar.set_description(\"epoch {} iter {}: train loss {:.5f}, f1 {:.2f}%, recall {:.2f}%, precision {:.2f}%, lr {:e}\"\\\n",
    "                                         .format(epoch+1,it,loss.item(),f1_score*100,recall_score*100,precision_score*100,lr))\n",
    "                    # pbar.set_description(f\"epoch {epoch+1} iter {it}: train loss {loss.item():.5f}, f1 {f1_score:.2f}, recall_score {recall_score:.5f}, lr {lr:e}\")\n",
    "\n",
    "            if not is_train:\n",
    "                valid_loss = float(np.mean(losses))\n",
    "                valid_f1_score, valid_recall_score, valid_precision_score = batch_score(spans_pred_all, spans_list_all)\n",
    "                logger.info(\"valid loss: {:.5f}\".format(valid_loss))\n",
    "                logger.info(\"valid f1 score: {:.2f}%\".format(valid_f1_score*100))\n",
    "                logger.info(\"valid recall: {:.2f}%\".format(valid_recall_score*100))\n",
    "                logger.info(\"valid precision: {:.2f}%\".format(valid_precision_score*100))\n",
    "                return valid_loss,valid_f1_score\n",
    "\n",
    "        self.tokens = 0 # counter used for learning rate decay\n",
    "        best_loss = float('inf')\n",
    "        best_valid_f1_score = 0.\n",
    "        # valid_loss = run_epoch('valid')\n",
    "        for epoch in range(config.max_epochs):\n",
    "            \n",
    "            run_epoch('train')\n",
    "            if self.valid_loader is not None:\n",
    "                valid_loss,valid_f1_score = run_epoch('valid')\n",
    "            # supports early stopping based on the valid loss, or just save always if no valid set is provided\n",
    "            good_model = self.valid_loader is None or valid_f1_score > best_valid_f1_score\n",
    "            if self.config.ckpt_path is not None and good_model:\n",
    "                best_valid_f1_score = valid_f1_score\n",
    "                self.save_checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "CCvFh5tyQx4e"
   },
   "outputs": [],
   "source": [
    "def decode_and_trans_labels(text_list, input_ids, logits):\n",
    "    token_labels = torch.argmax(logits, dim=-1).cpu().detach().numpy()\n",
    "    spans_pred = []\n",
    "    for ids, sentence, labels in zip(input_ids, text_list, token_labels):\n",
    "        tokens = tokenizer.convert_ids_to_tokens(ids)\n",
    "        position = 0\n",
    "        toxic_spans = []\n",
    "        token2span_list = []\n",
    "        # print(sentence)\n",
    "        for token, label in zip(tokens, labels):\n",
    "            if token in special_tokens.values():\n",
    "                continue\n",
    "            token = token.replace(\"##\",\"\")\n",
    "            spans = find_idx(sentence.lower(), token, position=position)\n",
    "            # print(token,spans)\n",
    "            if spans == []:\n",
    "                spans = list(range(position,position+len(token)))\n",
    "                print(\"not find:\",token,spans,position,\"\".join([sentence[i] for i in spans]))\n",
    "            position = spans[-1]+1\n",
    "            if label == 1:\n",
    "                toxic_spans.extend(spans)\n",
    "                token2span = (\"\".join([sentence[i] for i in spans])).lower()\n",
    "                if token != token2span:\n",
    "                    print(\"token: \",token)\n",
    "                    print(\"token2span: \",token2span)\n",
    "                token2span_list.append(token2span)\n",
    "        spans_pred.append(toxic_spans)\n",
    "        # print(\" \".join(token2span_list))\n",
    "    return spans_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "uQmYuB_fQzwk"
   },
   "outputs": [],
   "source": [
    "def f1(predictions, gold):\n",
    "    \"\"\"\n",
    "    F1 (a.k.a. DICE) operating on two lists of offsets (e.g., character).\n",
    "    >>> assert f1([0, 1, 4, 5], [0, 1, 6]) == 0.5714285714285714\n",
    "    :param predictions: a list of predicted offsets\n",
    "    :param gold: a list of offsets serving as the ground truth\n",
    "    :return: a score between 0 and 1\n",
    "    \"\"\"\n",
    "    if len(gold) == 0:\n",
    "        return 1. if len(predictions) == 0 else 0.\n",
    "    if len(predictions) == 0:\n",
    "        return 0.\n",
    "    predictions_set = set(predictions)\n",
    "    gold_set = set(gold)\n",
    "    nom = 2 * len(predictions_set.intersection(gold_set))\n",
    "    denom = len(predictions_set) + len(gold_set)\n",
    "    return float(nom)/float(denom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "0h0PRxuasMmd"
   },
   "outputs": [],
   "source": [
    "def recall(predictions, gold):\n",
    "    if len(gold) == 0:\n",
    "        return 1. if len(predictions) == 0 else 0.\n",
    "    if len(predictions) == 0:\n",
    "        return 0.\n",
    "    predictions_set = set(predictions)\n",
    "    gold_set = set(gold)\n",
    "    nom = len(predictions_set.intersection(gold_set))\n",
    "    denom = len(gold_set)\n",
    "    return float(nom)/float(denom)\n",
    "\n",
    "def precision(predictions, gold):\n",
    "    if len(gold) == 0:\n",
    "        return 1. if len(predictions) == 0 else 0.\n",
    "    if len(predictions) == 0:\n",
    "        return 0.\n",
    "    predictions_set = set(predictions)\n",
    "    gold_set = set(gold)\n",
    "    nom = len(predictions_set.intersection(gold_set))\n",
    "    denom = len(predictions_set)\n",
    "    return float(nom)/float(denom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "rwbwaKD_Q0U1"
   },
   "outputs": [],
   "source": [
    "def batch_score(spans_pred, spans_list):\n",
    "    f1_scores = []\n",
    "    recall_scores = []\n",
    "    precision_scores = []\n",
    "    for pred, gold in zip(spans_pred, spans_list):\n",
    "        f1_score = f1(pred, gold)\n",
    "        recall_score = recall(pred, gold)\n",
    "        precision_score = precision(pred, gold)\n",
    "        f1_scores.append(f1_score)\n",
    "        recall_scores.append(recall_score)\n",
    "        precision_scores.append(precision_score)\n",
    "    return np.mean(f1_scores), np.mean(recall_scores), np.mean(precision_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "2yZp_pa5L4y6"
   },
   "outputs": [],
   "source": [
    "class TrainerConfig:\n",
    "    # optimization parameters\n",
    "    max_epochs = 10\n",
    "    learning_rate = 1e-5\n",
    "    betas = (0.9, 0.95)\n",
    "    grad_norm_clip = 1.0\n",
    "    weight_decay = 0.1 # may useful optimize method\n",
    "    # learning rate decay params: linear warmup followed by cosine decay to 10% of original\n",
    "    lr_decay = False # optimize method\n",
    "    warmup_tokens = 375e6 # use this to train model from a lower learning rate\n",
    "    final_tokens = 260e9 # all tokens during whole training process\n",
    "    # checkpoint settings\n",
    "    ckpt_path = './models/' # save model path\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        for k,v in kwargs.items():\n",
    "            print(k,v)\n",
    "            setattr(self, k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Nv5Vk-UL41J",
    "outputId": "b2075804-7b22-4086-f58f-52dc59340649"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElectraForTokenClassification : all params: 334.094338M\n"
     ]
    }
   ],
   "source": [
    "# print model all parameters and parameters need training\n",
    "print('{} : all params: {:4f}M'.format(model._get_name(), sum(p.numel() for p in model.parameters()) / 1000 / 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_epochs 1\n",
      "learning_rate 1e-05\n",
      "lr_decay True\n",
      "warmup_tokens 4092\n",
      "final_tokens 40928\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 1\n",
    "final_tokens = max_epochs * batch_size * len(train_loader_aug)\n",
    "warmup_tokens = final_tokens//10\n",
    "tconf = TrainerConfig(max_epochs=max_epochs, learning_rate=1e-5, lr_decay=True, \n",
    "                      warmup_tokens=warmup_tokens, final_tokens=final_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, train_loader_aug, valid_loader, tconf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1279 [00:00<?, ?it/s]/home/suyinpei/anaconda3/envs/syp/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "epoch 1 iter 1278: train loss 0.06868, f1 52.56%, recall 48.99%, precision 63.89%, lr 1.000000e-06: 100%|██████████| 1279/1279 [19:55<00:00,  1.07it/s]\n",
      "04/29/2021 17:41:14 - valid loss: 0.14439\n",
      "04/29/2021 17:41:14 - valid f1 score: 49.39%\n",
      "04/29/2021 17:41:14 - valid recall: 47.15%\n",
      "04/29/2021 17:41:14 - valid precision: 59.82%\n",
      "04/29/2021 17:41:14 - Save model to ./models/\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JRl2WNjAL43U",
    "outputId": "097f1500-7de1-4324-82b4-bbbfa4372354"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_epochs 4\n",
      "learning_rate 1e-05\n",
      "lr_decay True\n",
      "warmup_tokens 3187\n",
      "final_tokens 31872\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 4\n",
    "final_tokens = max_epochs * batch_size * len(train_loader)\n",
    "warmup_tokens = final_tokens//10\n",
    "tconf = TrainerConfig(max_epochs=max_epochs, learning_rate=1e-5, lr_decay=True, \n",
    "                      warmup_tokens=warmup_tokens, final_tokens=final_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "QL4rnw7ZL45R"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(model, train_loader, valid_loader, tconf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h49l2wyeL47g",
    "outputId": "7a7fe398-bc6f-45ed-c09c-7dbb69c7ef7f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 248: train loss 0.12938, f1 72.87%, recall 70.09%, precision 100.00%, lr 9.330081e-06: 100%|██████████| 249/249 [03:51<00:00,  1.08it/s]\n",
      "04/29/2021 17:45:26 - valid loss: 0.12172\n",
      "04/29/2021 17:45:26 - valid f1 score: 63.36%\n",
      "04/29/2021 17:45:26 - valid recall: 61.04%\n",
      "04/29/2021 17:45:26 - valid precision: 76.02%\n",
      "04/29/2021 17:45:26 - Save model to ./models/\n",
      "epoch 2 iter 248: train loss 0.05339, f1 66.67%, recall 66.67%, precision 66.67%, lr 5.868181e-06: 100%|██████████| 249/249 [03:51<00:00,  1.08it/s]\n",
      "04/29/2021 17:49:41 - valid loss: 0.12797\n",
      "04/29/2021 17:49:41 - valid f1 score: 64.37%\n",
      "04/29/2021 17:49:41 - valid recall: 62.36%\n",
      "04/29/2021 17:49:41 - valid precision: 77.06%\n",
      "04/29/2021 17:49:41 - Save model to ./models/\n",
      "epoch 3 iter 248: train loss 0.09688, f1 89.74%, recall 84.31%, precision 100.00%, lr 1.786039e-06: 100%|██████████| 249/249 [03:51<00:00,  1.07it/s]\n",
      "04/29/2021 17:53:55 - valid loss: 0.12894\n",
      "04/29/2021 17:53:55 - valid f1 score: 65.69%\n",
      "04/29/2021 17:53:55 - valid recall: 64.85%\n",
      "04/29/2021 17:53:55 - valid precision: 76.73%\n",
      "04/29/2021 17:53:55 - Save model to ./models/\n",
      "epoch 4 iter 248: train loss 0.09164, f1 95.45%, recall 100.00%, precision 92.00%, lr 1.000000e-06: 100%|██████████| 249/249 [03:52<00:00,  1.07it/s]\n",
      "04/29/2021 17:58:12 - valid loss: 0.13728\n",
      "04/29/2021 17:58:12 - valid f1 score: 64.52%\n",
      "04/29/2021 17:58:12 - valid recall: 63.23%\n",
      "04/29/2021 17:58:12 - valid precision: 76.21%\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "-VigQ7VwtqAm"
   },
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('/content/gdrive/MyDrive/ToxicSpans/models/best_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OFjDhMEosFd5",
    "outputId": "1524c499-b636-491b-bd02-458b489b9c36"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('models/best_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "lZMwhLR8SkMP",
    "outputId": "0c6058e0-222e-4015-a401-b98bf7b08ecb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spans</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[84, 85, 86, 87, 88, 89, 90, 91, 133, 134, 135...</td>\n",
       "      <td>That's right. They are not normal. And I am st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[81, 82, 83, 84, 85, 86]</td>\n",
       "      <td>\"Watch people die from taking away their healt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>tens years ago i contacted the PDR and suggest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>The parallels between the ANC and the Sicilian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>Intel Community: ‘How can we work for a Presid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               spans  \\\n",
       "0  [84, 85, 86, 87, 88, 89, 90, 91, 133, 134, 135...   \n",
       "1                           [81, 82, 83, 84, 85, 86]   \n",
       "2                                                 []   \n",
       "3                                                 []   \n",
       "4                                                 []   \n",
       "\n",
       "                                                text  \n",
       "0  That's right. They are not normal. And I am st...  \n",
       "1  \"Watch people die from taking away their healt...  \n",
       "2  tens years ago i contacted the PDR and suggest...  \n",
       "3  The parallels between the ANC and the Sicilian...  \n",
       "4  Intel Community: ‘How can we work for a Presid...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsd_test = pd.read_csv(\"toxic_spans/data/tsd_test.csv\") \n",
    "tsd_test.text = tsd_test.text.apply(lambda x:x.translate(translationTable))\n",
    "tsd_test.spans = tsd_test.spans.apply(literal_eval)\n",
    "tsd_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "a-39QeDASpmJ"
   },
   "outputs": [],
   "source": [
    "text_list_test = tsd_test.text.to_list()\n",
    "spans_list_test = tsd_test.spans.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0hyZzdP3SskZ",
    "outputId": "8ce63267-c419-49c9-e8b7-82502ac76879"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "print(len(text_list_test))\n",
    "print(len(spans_list_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "6Xtsw5sftZhW"
   },
   "outputs": [],
   "source": [
    "def predict(text,spans):\n",
    "    input_ids,attention_mask,labels = encode_and_trans_labels([text], [spans])\n",
    "    outputs = model(input_ids.to(device), attention_mask.to(device), labels=labels.to(device).long())\n",
    "    logits = outputs.logits \n",
    "    spans_pred = decode_and_trans_labels([text], input_ids, logits)[0]\n",
    "    gold = \"\".join(text[i] for i in spans)\n",
    "    pred = \"\".join(text[i] for i in spans_pred)\n",
    "    # print(text)\n",
    "    # print(\"gold: {}\\npred: {}\".format(gold,pred))\n",
    "    f1_score = f1(spans_pred, spans)\n",
    "    recall_score = recall(spans_pred, spans)\n",
    "    precision_score = precision(spans_pred, spans)\n",
    "    # print(\"f1 {:.2f}%, recall {:.2f}%, precision {:.2f}%,\".format(f1_score*100,recall_score*100,precision_score*100))\n",
    "    return spans_pred, f1_score,recall_score,precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "Z1WzIGMyCR5S"
   },
   "outputs": [],
   "source": [
    "spans_pred, f1_score,recall_score,precision_score = predict(text_list_test[0],spans_list_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3BCuXUUPtZjd",
    "outputId": "65d36ff9-5680-4629-a2c4-b28ee6c2af19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All: f1 68.02%, recall 71.19%, precision 69.08%,\n"
     ]
    }
   ],
   "source": [
    "f1_scores,recall_scores,precision_scores = [],[],[]\n",
    "predictions = []\n",
    "for i in range(len(text_list_test)):\n",
    "    spans_pred, f1_score,recall_score,precision_score = predict(text_list_test[i],spans_list_test[i])\n",
    "    f1_scores.append(f1_score)\n",
    "    recall_scores.append(recall_score)\n",
    "    precision_scores.append(precision_score)\n",
    "    predictions.append(spans_pred)\n",
    "print(\"All: f1 {:.2f}%, recall {:.2f}%, precision {:.2f}%,\".format(np.mean(f1_scores)*100,np.mean(recall_scores)*100,np.mean(precision_scores)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E5-RAL4SS_7Z",
    "outputId": "830f8489-a569-41f1-d6d5-574b41436331"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t[118, 119, 120, 121, 122, 123, 126, 127, 128, 129, 130, 133, 134, 135, 136, 137, 138, 140, 141, 142, 143, 144, 145, 146]\n",
      "1\t[81, 82, 83, 84, 85, 86]\n",
      "2\t[483, 484, 485, 486, 487, 488, 489, 490]\n",
      "3\t[413, 414, 415, 416, 417, 418, 419, 420]\n",
      "4\t[]\n",
      "5\t[129, 130, 131, 132, 133, 134]\n",
      "6\t[35, 36, 37, 38, 39, 40, 41, 42, 43]\n",
      "7\t[55, 56, 57, 58, 59, 60, 61, 62]\n",
      "8\t[134, 135, 136, 137, 321, 322, 323, 324, 325, 326]\n",
      "9\t[94, 95, 96, 97]\n"
     ]
    }
   ],
   "source": [
    "# write in a prediction file named \"spans-pred.txt\"\n",
    "with open(\"spans-pred.txt\", \"w\") as out:\n",
    "    for it, text_scores in enumerate(predictions):\n",
    "        out.write(\"{}\\t{}\\n\".format(str(it),str(text_scores)))\n",
    "\n",
    "! head spans-pred.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "EE-ja7Kmx_kf"
   },
   "outputs": [],
   "source": [
    "# # mount my Google Drive directory and access the training data located there\n",
    "# from google.colab import drive\n",
    "# gdrive_dir = '/content/gdrive/'\n",
    "# drive.mount(gdrive_dir, force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "oUojR4tvx_mq"
   },
   "outputs": [],
   "source": [
    "# !cp -r models spans-pred.txt /content/gdrive/MyDrive/ToxicSpans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hizz1K7xsbvj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ToxicSpans_v4_use_trail.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0730a084aa4a4926841711e099242b66": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_195068b301e34121bf94b1f2ae26466e",
      "max": 27,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_23af761282a04e6787541cf8956d963c",
      "value": 27
     }
    },
    "195068b301e34121bf94b1f2ae26466e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "20b585c719c4416990562e924fda411d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "20f7d4b0e142411d97426d6b26766b81": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e8693669133e4e7d8eb891641d04a404",
      "placeholder": "​",
      "style": "IPY_MODEL_ec476a28a4144d68b09eb39fab1fe1ae",
      "value": " 27.0/27.0 [00:00&lt;00:00, 199B/s]"
     }
    },
    "21e445d606a143d6ad599668523ec7da": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_54eb2ccca1b84689ae3cc02deabc9fd9",
       "IPY_MODEL_31d43e06bf4c41ceade9758bf89d28ec"
      ],
      "layout": "IPY_MODEL_57e4fabc60f6407da277eef042ee5955"
     }
    },
    "23af761282a04e6787541cf8956d963c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "2450ea27dfe749d690d52a6adb0df8f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2748949795714def9ae46211d9a26935": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "286c30e0462a4dff9076b75aa3933703": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_66b05ef2743d49f182a63db56ed34270",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_20b585c719c4416990562e924fda411d",
      "value": 466062
     }
    },
    "2d4ad0920c9946d58c3591b834fc321e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2eaf2d8bd4b541d9a46da132f7e4e501": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31d43e06bf4c41ceade9758bf89d28ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2eaf2d8bd4b541d9a46da132f7e4e501",
      "placeholder": "​",
      "style": "IPY_MODEL_361b7ec51ba847c4a291bc409e1d1010",
      "value": " 1.34G/1.34G [00:34&lt;00:00, 38.8MB/s]"
     }
    },
    "361b7ec51ba847c4a291bc409e1d1010": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "388526bae29e43fd901423b040e4fdca": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "53fe88b22070493f8477ee24f9f1d86c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_286c30e0462a4dff9076b75aa3933703",
       "IPY_MODEL_bf0b1c6f927d47f1bdcd8d3ee9354234"
      ],
      "layout": "IPY_MODEL_85112c4d55f14fccb486a5ad73898c62"
     }
    },
    "54eb2ccca1b84689ae3cc02deabc9fd9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f61b392045c24f9d871bfab43164b1a8",
      "max": 1344867008,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_85ca440b2bcc4f0ca0b9b131a12e17e8",
      "value": 1344867008
     }
    },
    "57e4fabc60f6407da277eef042ee5955": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b903d2bcd1e41ba91114e2d42f83d99": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0730a084aa4a4926841711e099242b66",
       "IPY_MODEL_20f7d4b0e142411d97426d6b26766b81"
      ],
      "layout": "IPY_MODEL_2d4ad0920c9946d58c3591b834fc321e"
     }
    },
    "66b05ef2743d49f182a63db56ed34270": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7afd432af34c4e3eab15861550363787": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "7c49fa8b83854ff2bfdf878987536143": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "85112c4d55f14fccb486a5ad73898c62": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "85ca440b2bcc4f0ca0b9b131a12e17e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "8e2fe1d6c8b44ccdbf6387f5a083a588": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "91a6c01d5d504325823ea2ad3ea7e64c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_956b8371f8844f9ba716b6ededeacded",
       "IPY_MODEL_f909863f47584c97a491dc45389c90fe"
      ],
      "layout": "IPY_MODEL_2748949795714def9ae46211d9a26935"
     }
    },
    "956b8371f8844f9ba716b6ededeacded": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c6f44b8c16af4411a63e8312ed539a7b",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7afd432af34c4e3eab15861550363787",
      "value": 231508
     }
    },
    "a5eb5d9f44ec461ba0d37fdf71382dfe": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "afcdb17041fc42078c8227a570e23c1a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b1c2b0adacf446b4803918935f5f84b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e682f84e614246dbafd326a37755abca",
       "IPY_MODEL_cfc78163ca96469fa6fecea3f2b2c7cd"
      ],
      "layout": "IPY_MODEL_7c49fa8b83854ff2bfdf878987536143"
     }
    },
    "bdc6bae7c32b413280158502bda24845": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bf0b1c6f927d47f1bdcd8d3ee9354234": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ea1cc8393c7e44f9be293d0257246f2a",
      "placeholder": "​",
      "style": "IPY_MODEL_bdc6bae7c32b413280158502bda24845",
      "value": " 466k/466k [00:02&lt;00:00, 185kB/s]"
     }
    },
    "c6f44b8c16af4411a63e8312ed539a7b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cfc78163ca96469fa6fecea3f2b2c7cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_afcdb17041fc42078c8227a570e23c1a",
      "placeholder": "​",
      "style": "IPY_MODEL_a5eb5d9f44ec461ba0d37fdf71382dfe",
      "value": " 469/469 [00:04&lt;00:00, 117B/s]"
     }
    },
    "e682f84e614246dbafd326a37755abca": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8e2fe1d6c8b44ccdbf6387f5a083a588",
      "max": 469,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_388526bae29e43fd901423b040e4fdca",
      "value": 469
     }
    },
    "e8693669133e4e7d8eb891641d04a404": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea1cc8393c7e44f9be293d0257246f2a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ec476a28a4144d68b09eb39fab1fe1ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f61b392045c24f9d871bfab43164b1a8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f909863f47584c97a491dc45389c90fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fce5824b50b14ed3a04c85dadf2017a3",
      "placeholder": "​",
      "style": "IPY_MODEL_2450ea27dfe749d690d52a6adb0df8f6",
      "value": " 232k/232k [00:00&lt;00:00, 256kB/s]"
     }
    },
    "fce5824b50b14ed3a04c85dadf2017a3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
